{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function)\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgconnect_wk09(credential_filepath):\n",
    "    try:\n",
    "        with open(credential_filepath) as f:\n",
    "            db_conn_dict = json.load(f)\n",
    "        conn = psycopg2.connect(**db_conn_dict)\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "        return None\n",
    "    return conn\n",
    "\n",
    "def pgquery_wk09( conn, sqlcmd, args=None, msg=False, returntype='tuple'):\n",
    "    \"\"\" utility function to execute some SQL query statement\n",
    "        it can take optional arguments (as a dictionary) to fill in for placeholders in the SQL\n",
    "        will return the complete query result as return value - or in case of error: None\n",
    "        error and transaction handling built-in (by using the 'with' clauses)\"\"\"\n",
    "    retval = None\n",
    "    with conn:\n",
    "        cursortype = None if returntype != 'dict' else psycopg2.extras.RealDictCursor\n",
    "        with conn.cursor(cursor_factory=cursortype) as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if (cur.description != None ):\n",
    "                    retval = cur.fetchall() # we use fetchall() as we expect only _small_ query results\n",
    "                if msg != False:\n",
    "                    print(\"success: \" + msg)\n",
    "            except psycopg2.DatabaseError as e:\n",
    "                if e.pgcode != None:\n",
    "                    if msg: print(\"db read error: \"+msg)\n",
    "                    print(e)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this file and insert your unikey and sid\n",
    "credfilepath = \"data2x01_db.json\"\n",
    "conn_wk09 = pgconnect_wk09(credfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgis_check = '''\n",
    "SELECT PostGIS_Version();\n",
    "'''\n",
    "pgquery_wk09(conn_wk09,postgis_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_creation = '''CREATE SCHEMA IF NOT EXISTS assignment;'''\n",
    "pgquery_wk09(conn_wk09, \"DROP SCHEMA IF EXISTS assignment CASCADE\", msg=\"cleared old schema\")\n",
    "pgquery_wk09(conn_wk09, schema_creation, msg=\"created schema assignment\")\n",
    "\n",
    "#schema_permission1 = '''GRANT ALL ON SCHEMA assignment TO y20s1d2x01_mile3211;'''\n",
    "#schema_permission2 = '''GRANT ALL ON SCHEMA assignment TO y20s1d2x01_ktru7823;'''\n",
    "#schema_permission3 = '''GRANT ALL ON SCHEMA assignment TO y20s1d2x01_xidu5391;'''\n",
    "#pgquery_wk09(conn_wk09, schema_permission1, msg=\"permission granted\")\n",
    "#pgquery_wk09(conn_wk09, schema_permission2, msg=\"permission granted\")\n",
    "#pgquery_wk09(conn_wk09, schema_permission3, msg=\"permission granted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_services_df = pd.read_csv('HealthServices.csv')\n",
    "neighbourhoods_df = pd.read_csv('Neighbourhoods.csv')\n",
    "nsw_postcodes_df = pd.read_csv('NSW_Postcodes.csv')\n",
    "population_stats_df = pd.read_csv('PopulationStats2016.csv')\n",
    "statistical_areas_df = pd.read_csv('StatisticalAreas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statistical_areas_schema = '''CREATE TABLE IF NOT EXISTS assignment.statistical_areas (\n",
    "    area_id           VARCHAR(20) PRIMARY KEY,\n",
    "    area_name         VARCHAR(100),\n",
    "    parent_area_id    VARCHAR(20)\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.statistical_areas\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, statistical_areas_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.statistical_areas VALUES ( %(area_id)s, %(area_name)s, %(parent_area_id)s\n",
    "                    )\"\"\"\n",
    "\n",
    "for index, row in statistical_areas_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "# expect 414 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use url for covid data?\n",
    "import requests\n",
    "url = 'https://data.nsw.gov.au/data/dataset/5424aa3b-550d-4637-ae50-7f458ce327f4/resource/227f6b65-025c-482c-9f22-a25cf1b8594f/download/covid-19-tests-by-date-and-location-and-result.csv'  \n",
    "\n",
    "req = requests.get(url)\n",
    "covid_csv_data = open('covid-19-tests-by-date-and-location-and-result.csv', 'wb').write(req.content)\n",
    "\n",
    "covid_tests_df = pd.read_csv('covid-19-tests-by-date-and-location-and-result.csv')\n",
    "\n",
    "# or just use downloaded data\n",
    "# covid_tests_df = pd.read_csv('covid-19-tests-by-date-and-location-and-result-may-8.csv')\n",
    "\n",
    "# covid_tests_clean_df = covid_tests_df.dropna();\n",
    "covid_tests_clean_df = covid_tests_df.dropna(subset=['postcode'], inplace=False)\n",
    "\n",
    "# convert postcode to ints\n",
    "# semi convoluted manner, but directly changing it throws a warning for some reason\n",
    "covid_tests_clean_df2 = covid_tests_clean_df.copy(deep=True)\n",
    "covid_tests_clean_df2[\"postcode\"] = covid_tests_clean_df[\"postcode\"].astype(int)\n",
    "covid_tests_clean_df = covid_tests_clean_df2\n",
    "covid_tests_clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_tests_schema = '''CREATE TABLE IF NOT EXISTS assignment.covid_19_tests (\n",
    "    test_date       DATE NOT NULL,\n",
    "    postcode        VARCHAR(4) NOT NULL,\n",
    "    lhd_2010_code   CHAR(4),\n",
    "    lhd_2010_name   VARCHAR(100),\n",
    "    lga_code19      FLOAT,\n",
    "    lga_name19      VARCHAR(100),\n",
    "    result          VARCHAR(20) NOT NULL\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.covid_19_tests\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, covid_tests_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.covid_19_tests (test_date, postcode, lhd_2010_code, lhd_2010_name,\n",
    "                    lga_code19, lga_name19, result)\n",
    "                    SELECT %(test_date)s, %(postcode)s, %(lhd_2010_code)s,\n",
    "                    %(lhd_2010_name)s, %(lga_code19)s, %(lga_name19)s, %(result)s;\"\"\"\n",
    "\n",
    "# this takes forever but pls do not interrupt\n",
    "for index, row in covid_tests_clean_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "# TODO: is there a faster way\n",
    "# expect 200 000+ rows (may 8)\n",
    "# expect 400 000+ rows (recent)\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result\n",
    "\n",
    "# fixing up the table\n",
    "\n",
    "# a possible foreign key? but postcodes aren't unique\n",
    "# ALTER TABLE assignment.covid_19_tests\n",
    "#    ADD CONSTRAINT FK_covid_tests_postcode FOREIGN KEY (postcode) REFERENCES assignment.nsw_postcodes(postcode)\n",
    "\n",
    "alter_table_command = '''ALTER TABLE assignment.covid_19_tests\n",
    "                            ALTER COLUMN lga_code19 TYPE CHAR(5) USING CAST(ROUND(lga_code19) AS CHAR(5));'''\n",
    "pgquery_wk09(conn_wk09, alter_table_command)\n",
    "\n",
    "index_command = \"CREATE INDEX covid_tests_idx ON assignment.covid_19_tests(postcode, result)\"\n",
    "result = pgquery_wk09(conn_wk09, index_command, returntype='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsw_shp_schema = '''CREATE TABLE assignment.nsw_shp (\n",
    "                        sa2_main16   VARCHAR(20) PRIMARY KEY,\n",
    "                        sa2_5dig16   VARCHAR(20),\n",
    "                        sa2_name16   VARCHAR(50),\n",
    "                        sa3_code16   VARCHAR(20),\n",
    "                        sa3_name16   VARCHAR(50),\n",
    "                        sa4_code16   VARCHAR(20),\n",
    "                        sa4_name16   VARCHAR(50),\n",
    "                        gcc_code16   CHAR(5),\n",
    "                        gcc_name16   VARCHAR(50),\n",
    "                        ste_code16   VARCHAR(20),\n",
    "                        ste_name16   VARCHAR(50),\n",
    "                        area_sq_km16 FLOAT,\n",
    "                        geometry     GEOMETRY(MULTIPOLYGON, 4283)\n",
    ")''' \n",
    "\n",
    "table_name = \"assignment.nsw_shp\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name+\" CASCADE\", msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, nsw_shp_schema, msg=\"created \"+table_name)\n",
    "\n",
    "nsw_shp_df = gpd.read_file( \"1270055001_sa2_2016_aust_shape/SA2_2016_AUST.shp\" )\n",
    "nsw_shp_df['geom_wkt'] = nsw_shp_df['geometry'].apply(lambda x: x.wkt if x is not None else x)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.nsw_shp VALUES ( %(SA2_MAIN16)s, %(SA2_5DIG16)s, %(SA2_NAME16)s,\n",
    "                    %(SA3_CODE16)s, %(SA3_NAME16)s, %(SA4_CODE16)s, %(SA4_NAME16)s, %(GCC_CODE16)s,\n",
    "                    %(GCC_NAME16)s, %(STE_CODE16)s, %(STE_NAME16)s, %(AREASQKM16)s,\n",
    "                    ST_Multi(ST_GeomFromText( %(geom_wkt)s,4283)) )\"\"\"\n",
    "\n",
    "for idx, location in nsw_shp_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=location)\n",
    "\n",
    "\n",
    "\n",
    "index_command = \"CREATE INDEX nsw_shp_idx ON assignment.nsw_shp USING GIST (geometry)\"\n",
    "pgquery_wk09(conn_wk09, index_command, returntype='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect 2310 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_filepath = \"Commutes2011.json\"\n",
    "commutes_df = pd.read_json(commute_filepath)\n",
    "commutes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "\n",
    "commutes_expanded_df = pd.DataFrame(columns = [\"origin\", \"destination\", \"people\"])\n",
    "\n",
    "# this takes a couple of minutes but pls do not interrupt\n",
    "for index, row in commutes_df.iterrows():\n",
    "    expanded_row = pd.concat([pd.DataFrame(json_normalize(x)) for x in row[\"destinations\"]],ignore_index=True)\n",
    "    origin_value = row[\"origin\"]\n",
    "    expanded_row[\"origin\"] = origin_value\n",
    "    expanded_row = expanded_row[[\"origin\", \"destination\", \"people\"]]\n",
    "    commutes_expanded_df = commutes_expanded_df.append(expanded_row)\n",
    "\n",
    "commutes_grouped_df = commutes_expanded_df.groupby([\"origin\",\"destination\"]).sum().reset_index()\n",
    "commutes_grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commutes_schema = '''CREATE TABLE IF NOT EXISTS assignment.commutes (\n",
    "    origin       VARCHAR(20),\n",
    "    destination  VARCHAR(20),\n",
    "    people       INTEGER,\n",
    "    CONSTRAINT PK_commutes PRIMARY KEY (origin, destination)\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.commutes\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, commutes_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.commutes VALUES ( %(origin)s, %(destination)s, %(people)s\n",
    "                )\"\"\"\n",
    "\n",
    "# this takes a while but pls do not interrupt\n",
    "for idx, row in commutes_grouped_df.iterrows():\n",
    "    origin = str(row[\"origin\"])\n",
    "    destination = str(row[\"destination\"])\n",
    "    people = str(row[\"people\"])\n",
    "    pgquery_wk09(conn_wk09,\n",
    "                 \"\"\"INSERT INTO assignment.commutes VALUES ( \"\"\" + origin + \"\"\",\n",
    "                         \"\"\" + destination + \"\"\", \"\"\" + people + \"\"\")\"\"\",\n",
    "                 args=row)\n",
    "\n",
    "# expect 65065 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_services_schema = '''CREATE TABLE IF NOT EXISTS assignment.health_services (\n",
    "    id          INTEGER PRIMARY KEY,\n",
    "    name        VARCHAR(100),\n",
    "    category    VARCHAR(100),\n",
    "    num_beds    FLOAT,\n",
    "    address     VARCHAR(1000),\n",
    "    suburb      VARCHAR(100),\n",
    "    state       CHAR(3),\n",
    "    postcode    CHAR(4) NOT NULL,\n",
    "    latitude    FLOAT   NOT NULL,\n",
    "    longitude   FLOAT   NOT NULL,\n",
    "    comment     VARCHAR(4000),\n",
    "    website     VARCHAR(200)\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.health_services\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, health_services_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.health_services VALUES ( %(id)s, %(name)s, %(category)s,\n",
    "                    %(num_beds)s, %(address)s, %(suburb)s, %(state)s, %(postcode)s,\n",
    "                    %(latitude)s, %(longitude)s, %(comment)s, %(website)s\n",
    "                    )\"\"\"\n",
    "\n",
    "for index, row in health_services_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "# expect 3026 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result\n",
    "\n",
    "health_services_add_column = '''ALTER TABLE assignment.health_services\n",
    "                               ADD point GEOMETRY(POINT, 4283)\n",
    "'''\n",
    "pgquery_wk09(conn_wk09, health_services_add_column, msg=\"added column in \"+table_name)\n",
    "\n",
    "health_services_update_values = '''UPDATE assignment.health_services\n",
    "                                SET point = ST_SetSRID(ST_MakePoint(longitude, latitude), 4283)\n",
    "'''\n",
    "pgquery_wk09(conn_wk09, health_services_update_values, msg=\"updated values in \"+table_name)\n",
    "\n",
    "# spatial index for health services\n",
    "index_command = \"CREATE INDEX health_services_pt_idx ON assignment.health_services USING GIST (point)\"\n",
    "result = pgquery_wk09(conn_wk09, index_command, returntype='dict')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas uses NaN (a float) to represent missing values, so the data types\n",
    "# (population, dwellings, businesses, median_income, avg_monthly_rent) need to be floats\n",
    "neighbourhoods_schema = '''CREATE TABLE IF NOT EXISTS assignment.neighbourhoods (\n",
    "    area_id           VARCHAR(20) PRIMARY KEY REFERENCES assignment.nsw_shp(sa2_main16),\n",
    "    area_name         VARCHAR(100),\n",
    "    land_area         FLOAT,\n",
    "    population        FLOAT,\n",
    "    dwellings         FLOAT,\n",
    "    businesses        FLOAT,\n",
    "    median_income     FLOAT,\n",
    "    avg_monthly_rent  FLOAT\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.neighbourhoods\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name+\" CASCADE\", msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, neighbourhoods_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.neighbourhoods VALUES ( %(area_id)s, %(area_name)s, %(land_area)s,\n",
    "                    %(population)s, %(number_of_dwellings)s, %(number_of_businesses)s,\n",
    "                    %(median_annual_household_income)s, %(avg_monthly_rent)s\n",
    "                    )\"\"\"\n",
    "\n",
    "for index, row in neighbourhoods_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "# cleaning\n",
    "update_command = \"\"\"UPDATE assignment.neighbourhoods\n",
    "SET population = 0\n",
    "WHERE population = 'NaN';\"\"\"\n",
    "pgquery_wk09(conn_wk09, update_command)\n",
    "\n",
    "# expect 312 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsw_postcodes_schema = '''CREATE TABLE IF NOT EXISTS assignment.nsw_postcodes (\n",
    "    id        INTEGER PRIMARY KEY,\n",
    "    postcode  CHAR(4) NOT NULL,\n",
    "    locality  VARCHAR(50),\n",
    "    longitude FLOAT,\n",
    "    latitude  FLOAT\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.nsw_postcodes\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, nsw_postcodes_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.nsw_postcodes VALUES ( %(id)s, %(postcode)s, %(locality)s,\n",
    "                    %(longitude)s, %(latitude)s\n",
    "                    )\"\"\"\n",
    "\n",
    "for index, row in nsw_postcodes_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "index_command = \"CREATE INDEX nsw_postcodes_idx ON assignment.nsw_postcodes(postcode)\"\n",
    "pgquery_wk09(conn_wk09, index_command, returntype='dict')\n",
    "\n",
    "# expect 5639 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_stats_schema = '''CREATE TABLE IF NOT EXISTS assignment.population_stats_2016 (\n",
    "    area_id         VARCHAR(20) PRIMARY KEY REFERENCES assignment.nsw_shp(sa2_main16),\n",
    "    area_name       VARCHAR(100),\n",
    "    \"0-4\"           INTEGER,\n",
    "    \"5-9\"           INTEGER,\n",
    "    \"10-14\"         INTEGER,\n",
    "    \"15-19\"         INTEGER,\n",
    "    \"20-24\"         INTEGER,\n",
    "    \"25-29\"         INTEGER,\n",
    "    \"30-34\"         INTEGER,\n",
    "    \"35-39\"         INTEGER,\n",
    "    \"40-44\"         INTEGER,\n",
    "    \"45-49\"         INTEGER,\n",
    "    \"50-54\"         INTEGER,\n",
    "    \"55-59\"         INTEGER,\n",
    "    \"60-64\"         INTEGER,\n",
    "    \"65-69\"         INTEGER,\n",
    "    \"70-74\"         INTEGER,\n",
    "    \"75-79\"         INTEGER,\n",
    "    \"80-84\"         INTEGER,\n",
    "    \"85_and_over\"   INTEGER,\n",
    "    total_persons   INTEGER,\n",
    "    females         INTEGER,\n",
    "    males           INTEGER\n",
    ")'''\n",
    "\n",
    "table_name = \"assignment.population_stats_2016\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, population_stats_schema, msg=\"created \"+table_name)\n",
    "\n",
    "insert_stmt = \"\"\"INSERT INTO assignment.population_stats_2016 VALUES ( %(area_id)s, %(area_name)s,\n",
    "                    %(0-4)s, %(5-9)s, %(10-14)s, %(15-19)s, %(20-24)s, %(25-29)s, %(30-34)s, %(35-39)s,\n",
    "                    %(40-44)s, %(45-49)s, %(50-54)s, %(55-59)s, %(60-64)s, %(65-69)s, %(70-74)s, %(75-79)s,\n",
    "                    %(80-84)s, %(85_and_over)s, %(total_persons)s, %(females)s, %(males)s\n",
    "                    )\"\"\"\n",
    "\n",
    "for index, row in population_stats_df.iterrows():\n",
    "    pgquery_wk09(conn_wk09, insert_stmt, args=row)\n",
    "\n",
    "# expect 576 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population density = population divided by neighbourhood's land area\n",
    "# population age = proportion of people aged 70+ (set to zero if no population)\n",
    "# health service density = number of health services per neighbourhood per 1000 people\n",
    "# hospital bed density = number of hospital beds per neighbourhood per 1000 people\n",
    "# commuter density = number of people commuting per neighbourhood per (1000 people?)\n",
    "\n",
    "all_query = \"\"\"\n",
    "WITH\n",
    "neighbourhoods_with_geom AS (\n",
    "    SELECT area_id, population, geometry\n",
    "    FROM (assignment.neighbourhoods JOIN assignment.nsw_shp ON (area_id = sa2_main16))\n",
    "),\n",
    "pop_dens AS (\n",
    "    SELECT area_id, (population / land_area) AS population_density\n",
    "    FROM assignment.neighbourhoods\n",
    "),\n",
    "pop_age AS (\n",
    "    SELECT area_id, \n",
    "            COALESCE(( CAST(\"70-74\" AS FLOAT)\n",
    "                        + CAST(\"75-79\" AS FLOAT)\n",
    "                        + CAST(\"80-84\" AS FLOAT)\n",
    "                        + CAST(\"85_and_over\" AS FLOAT) )\n",
    "                        / NULLIF(CAST(\"total_persons\" AS FLOAT), 0), 0)\n",
    "                        AS population_age\n",
    "    FROM assignment.population_stats_2016 A\n",
    "    WHERE EXISTS (SELECT 1\n",
    "                    FROM assignment.neighbourhoods B\n",
    "                    WHERE A.area_id = B.area_id)\n",
    "),\n",
    "health_dens AS (\n",
    "    SELECT area_id,\n",
    "        CASE\n",
    "            WHEN population = 0\n",
    "            THEN 0\n",
    "            ELSE CAST(COUNT(area_id) AS FLOAT) / (population/1000.0)\n",
    "        END AS health_service_density,\n",
    "        CASE\n",
    "            WHEN population = 0\n",
    "            THEN 0\n",
    "            ELSE SUM(COALESCE(NULLIF(num_beds, 'NaN'), 0)) / (population/1000.0)\n",
    "        END AS hospital_bed_density\n",
    "    FROM neighbourhoods_with_geom A LEFT JOIN assignment.health_services B\n",
    "            ON (ST_Intersects(A.geometry, B.point))\n",
    "    GROUP BY area_id, population\n",
    "),\n",
    "comm_dens AS (\n",
    "    SELECT area_id,\n",
    "            CAST(total_commuters AS FLOAT) / (population/1000.0)\n",
    "                AS commuter_density\n",
    "    FROM assignment.neighbourhoods LEFT JOIN (SELECT origin, SUM(people) AS total_commuters\n",
    "                                FROM assignment.commutes\n",
    "                                GROUP BY origin\n",
    "                                ORDER BY origin) AS commutes_by_origin\n",
    "            ON (origin = area_id)\n",
    "    GROUP BY area_id, total_commuters\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "INTO assignment.vulnerability_measures\n",
    "FROM pop_dens NATURAL JOIN pop_age NATURAL JOIN health_dens NATURAL JOIN comm_dens\n",
    "ORDER BY area_id;\n",
    "\"\"\"\n",
    "\n",
    "table_name = \"assignment.vulnerability_measures\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, all_query, msg=\"created \"+table_name)\n",
    "\n",
    "pk_command = '''ALTER TABLE assignment.vulnerability_measures ADD PRIMARY KEY (area_id);'''\n",
    "pgquery_wk09(conn_wk09, pk_command)\n",
    "\n",
    "fk_command = '''ALTER TABLE assignment.vulnerability_measures\n",
    "                ADD CONSTRAINT fk_vuln_measures FOREIGN KEY (area_id) REFERENCES assignment.neighbourhoods(area_id);'''\n",
    "pgquery_wk09(conn_wk09, fk_command)\n",
    "\n",
    "# expect 312 rows, one for each area_id in neighbourhoods in sydney\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vulnerability = S( z(population density) + z(population age) - z(healthservice density) - z(hospitalbed density) )\n",
    "# z(measure; x) = ( x - avg(measure) ) / std.dev(measure)\n",
    "\n",
    "z_score_query = \"\"\"WITH\n",
    "area_ids AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\", area_id\n",
    "        FROM assignment.vulnerability_measures\n",
    "),\n",
    "pd_z AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\",\n",
    "                (population_density - (AVG(population_density) OVER ()) )\n",
    "                / (STDDEV_POP(population_density) OVER ()) AS pd_z_score\n",
    "        FROM assignment.vulnerability_measures\n",
    "),\n",
    "pa_z AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\",\n",
    "                (population_age - (AVG(population_age) OVER ()) )\n",
    "                / (STDDEV_POP(population_age) OVER ()) AS pa_z_score\n",
    "        FROM assignment.vulnerability_measures\n",
    "),\n",
    "hsd_z AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\",\n",
    "                    (health_service_density - (AVG(health_service_density) OVER ()) )\n",
    "                    / (STDDEV_POP(health_service_density) OVER ()) AS hsd_z_score\n",
    "        FROM assignment.vulnerability_measures\n",
    "),\n",
    "hbd_z AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\",\n",
    "                    (hospital_bed_density - (AVG(hospital_bed_density) OVER ()) )\n",
    "                    / (STDDEV_POP(hospital_bed_density) OVER ()) AS hbd_z_score\n",
    "        FROM assignment.vulnerability_measures\n",
    "),\n",
    "cd_z AS (\n",
    "    SELECT ROW_NUMBER() OVER () AS \"id\",\n",
    "                    COALESCE((commuter_density - (AVG(commuter_density) OVER ()) )\n",
    "                    / (STDDEV_POP(commuter_density) OVER ()), 0) AS cd_z_score\n",
    "        FROM assignment.vulnerability_measures\n",
    ")\n",
    "\n",
    "SELECT area_id, pd_z_score, pa_z_score, hsd_z_score, hbd_z_score, cd_z_score\n",
    "INTO assignment.vulnerability_z_scores\n",
    "FROM area_ids NATURAL JOIN pd_z NATURAL JOIN pa_z\n",
    "        NATURAL JOIN hsd_z NATURAL JOIN hbd_z NATURAL JOIN cd_z;\"\"\"\n",
    "\n",
    "table_name = \"assignment.vulnerability_z_scores\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, z_score_query, msg=\"created \"+table_name)\n",
    "\n",
    "pk_command = '''ALTER TABLE assignment.vulnerability_z_scores ADD PRIMARY KEY (area_id);'''\n",
    "pgquery_wk09(conn_wk09, pk_command)\n",
    "\n",
    "fk_command = '''ALTER TABLE assignment.vulnerability_z_scores\n",
    "                ADD CONSTRAINT fk_z_score FOREIGN KEY (area_id) REFERENCES assignment.neighbourhoods(area_id);'''\n",
    "pgquery_wk09(conn_wk09, fk_command)\n",
    "\n",
    "# expect 312 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerability_final_score_schema = '''\n",
    "SELECT area_id,\n",
    "        (1 / (1 + exp(-(pd_z_score + pa_z_score - hsd_z_score - hbd_z_score)))) AS vuln_score_no_commute,\n",
    "        (1 / (1 + exp(-(pd_z_score + pa_z_score - hsd_z_score - hbd_z_score + cd_z_score)))) AS final_vuln_score\n",
    "INTO assignment.vulnerability_final_scores\n",
    "FROM assignment.vulnerability_z_scores;\n",
    "'''\n",
    "\n",
    "table_name = \"assignment.vulnerability_final_scores\"\n",
    "pgquery_wk09(conn_wk09, \"DROP TABLE IF EXISTS \"+table_name, msg=\"cleared old table\")\n",
    "pgquery_wk09(conn_wk09, vulnerability_final_score_schema, msg=\"created \"+table_name)\n",
    "\n",
    "pk_command = '''ALTER TABLE assignment.vulnerability_final_scores ADD PRIMARY KEY (area_id);'''\n",
    "pgquery_wk09(conn_wk09, pk_command)\n",
    "\n",
    "fk_command = '''ALTER TABLE assignment.vulnerability_final_scores\n",
    "                ADD CONSTRAINT fk_vulnerability_final_scores FOREIGN KEY (area_id) REFERENCES assignment.neighbourhoods(area_id);'''\n",
    "pgquery_wk09(conn_wk09, fk_command)\n",
    "\n",
    "# expect 312 rows\n",
    "result = pgquery_wk09(conn_wk09, 'SELECT COUNT(*) FROM '+table_name)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_query = \"\"\"\n",
    "WITH\n",
    "neighbourhoods_with_geom AS (\n",
    "    SELECT area_id, gcc_code16, population, geometry\n",
    "         FROM (assignment.neighbourhoods JOIN assignment.nsw_shp ON (area_id = sa2_main16))\n",
    "),\n",
    "postcode_with_geom AS (\n",
    "SELECT postcode, AVG(longitude) AS avg_longitude, AVG(latitude) AS avg_latitude,\n",
    "                ST_SetSRID(ST_MakePoint(AVG(longitude), AVG(latitude)), 4283) AS point\n",
    "            FROM assignment.nsw_postcodes\n",
    "            GROUP BY postcode\n",
    "            ORDER BY postcode\n",
    "),\n",
    "cases_by_postcode_with_geom AS (\n",
    "    SELECT postcode, positive_result_count, avg_longitude, avg_latitude, point\n",
    "    FROM (SELECT postcode, result,\n",
    "                COUNT(result) AS positive_result_count\n",
    "            FROM assignment.covid_19_tests\n",
    "            WHERE result = 'Case - Confirmed'\n",
    "            GROUP BY postcode, result\n",
    "            ORDER BY postcode) AS positive_cases\n",
    "        JOIN postcode_with_geom USING (postcode)\n",
    "),\n",
    "tests_by_postcode_with_geom AS (\n",
    "    SELECT postcode, test_count, avg_longitude, avg_latitude, point\n",
    "    FROM (SELECT postcode, result,\n",
    "                COUNT(result) AS test_count\n",
    "            FROM assignment.covid_19_tests\n",
    "            GROUP BY postcode, result\n",
    "            ORDER BY postcode) AS total_tests_by_postcode\n",
    "        JOIN postcode_with_geom USING (postcode)\n",
    "),\n",
    "cases_by_area_id AS (\n",
    "    SELECT area_id, SUM(positive_result_count) AS positive_result_count\n",
    "    FROM neighbourhoods_with_geom A LEFT JOIN cases_by_postcode_with_geom B\n",
    "                    ON (ST_Intersects(A.geometry, B.point))\n",
    "    GROUP BY area_id\n",
    "    ORDER BY area_id\n",
    "),\n",
    "tests_by_area_id AS (\n",
    "    SELECT area_id, SUM(test_count) AS total_test_count\n",
    "    FROM neighbourhoods_with_geom A LEFT JOIN tests_by_postcode_with_geom B\n",
    "                    ON (ST_Intersects(A.geometry, B.point))\n",
    "    GROUP BY area_id\n",
    "    ORDER BY area_id\n",
    ")\n",
    "\n",
    "SELECT positive_result_count AS \"Positive COVID-19 cases\", total_test_count AS \"Total COVID-19 tests\",\n",
    "            vuln_score_no_commute AS \"Vulnerability Score (no commutes)\", final_vuln_score AS \"Vulnerability Score\"\n",
    "FROM (cases_by_area_id\n",
    "        JOIN tests_by_area_id USING (area_id))\n",
    "        JOIN assignment.vulnerability_final_scores USING (area_id);\n",
    "\"\"\"\n",
    "\n",
    "correlation_df = pd.read_sql(correlation_query, conn_wk09)\n",
    "correlation_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.plot.scatter(x='Positive COVID-19 cases',y='Vulnerability Score')\n",
    "plt.savefig('figure_scatter1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well a lot of the commute counts were null so its pretty similar\n",
    "correlation_df.plot.scatter(x='Positive COVID-19 cases',y='Vulnerability Score (no commutes)')\n",
    "plt.savefig('figure_scatter2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.plot.scatter(x='Total COVID-19 tests',y='Vulnerability Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.plot.scatter(x='Total COVID-19 tests',y='Vulnerability Score (no commutes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map plot v2\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT area_id, final_vuln_score, geometry\n",
    "FROM assignment.vulnerability_final_scores\n",
    "    JOIN assignment.nsw_shp ON (area_id = sa2_main16);\n",
    "\"\"\"\n",
    "\n",
    "gdf = gpd.read_postgis(query2, conn_wk09, geom_col='geometry')\n",
    "sa2 = gpd.read_file('1270055001_sa2_2016_aust_shape/SA2_2016_AUST.shp')\n",
    "\n",
    "ax = sa2.plot(color='white', edgecolor='grey', figsize=(20,20))\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "bounds = gdf.geometry.bounds\n",
    "\n",
    "plt.xlim([bounds.minx.min()-0.15, bounds.maxx.max()+0.15])\n",
    "plt.ylim([bounds.miny.min()-0.15, bounds.maxy.max()+0.15])\n",
    "\n",
    "gdf.plot(ax=ax, column='final_vuln_score', cmap='OrRd', legend=True,\n",
    "                 legend_kwds={'label': \"Vulnerability Score\"})\n",
    "\n",
    "plt.savefig('figure_vv_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map plot for positive cases\n",
    "\n",
    "query2 = \"\"\"\n",
    "WITH\n",
    "neighbourhoods_with_geom AS (\n",
    "    SELECT area_id, gcc_code16, population, geometry\n",
    "         FROM (assignment.neighbourhoods JOIN assignment.nsw_shp ON (area_id = sa2_main16))\n",
    "),\n",
    "postcode_with_geom AS (\n",
    "SELECT postcode, AVG(longitude) AS avg_longitude, AVG(latitude) AS avg_latitude,\n",
    "                ST_SetSRID(ST_MakePoint(AVG(longitude), AVG(latitude)), 4283) AS point\n",
    "            FROM assignment.nsw_postcodes\n",
    "            GROUP BY postcode\n",
    "            ORDER BY postcode\n",
    "),\n",
    "cases_by_postcode_with_geom AS (\n",
    "    SELECT postcode, positive_result_count, avg_longitude, avg_latitude, point\n",
    "    FROM (SELECT postcode, result,\n",
    "                COUNT(result) AS positive_result_count\n",
    "            FROM assignment.covid_19_tests\n",
    "            WHERE result = 'Case - Confirmed'\n",
    "            GROUP BY postcode, result\n",
    "            ORDER BY postcode) AS positive_cases\n",
    "        JOIN postcode_with_geom USING (postcode)\n",
    ")\n",
    "\n",
    "SELECT area_id, SUM(positive_result_count) AS positive_result_count, geometry\n",
    "FROM neighbourhoods_with_geom A LEFT JOIN cases_by_postcode_with_geom B\n",
    "                    ON (ST_Intersects(A.geometry, B.point))\n",
    "GROUP BY area_id, geometry\n",
    "ORDER BY area_id;\n",
    "\"\"\"\n",
    "\n",
    "gdf = gpd.read_postgis(query2, conn_wk09, geom_col='geometry')\n",
    "sa2 = gpd.read_file('1270055001_sa2_2016_aust_shape/SA2_2016_AUST.shp')\n",
    "\n",
    "ax = sa2.plot(color='white', edgecolor='grey', figsize=(20,20))\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "bounds = gdf.geometry.bounds\n",
    "\n",
    "plt.xlim([bounds.minx.min()-0.15, bounds.maxx.max()+0.15])\n",
    "plt.ylim([bounds.miny.min()-0.15, bounds.maxy.max()+0.15])\n",
    "\n",
    "gdf.plot(ax=ax, column='positive_result_count', cmap='OrRd', legend=True,\n",
    "                 legend_kwds={'label': \"Number of positive cases\"})\n",
    "\n",
    "plt.savefig('figure_positive_cases.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_wk09.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
